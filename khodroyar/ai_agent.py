import os
import json
from datetime import datetime
from typing import List, Dict, Optional
import openai
import jdatetime
from django.conf import settings
from .models import Conversation, Message
from .car_search import get_car_search_service


class KhodroyarAIAgent:
    """AI Agent for Khodroyar chatbot using Aval AI API with GPT-4.1"""
    
    def __init__(self):
        """Initialize the AI agent with Aval AI configuration"""
        self.base_url = settings.AVAL_AI_BASE_URL
        self.api_key = settings.AVAL_AI_API_KEY
        
        if not self.api_key:
            raise ValueError("AVAL_AI_API_KEY is not configured in environment variables")
        
        # Configure OpenAI client for Aval AI
        # Try different initialization approaches
        try:
            # First try with minimal configuration
            self.client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
        except Exception as e:
            print(f"Failed to initialize OpenAI client with base_url: {e}")
            # Fallback to standard OpenAI client
            self.client = openai.OpenAI(
                api_key=self.api_key
            )
            print("Using standard OpenAI client as fallback")
        
        # Initialize car search service
        self.car_search_service = get_car_search_service()
        
        # Define available functions for the AI
        self.available_functions = [
            {
                "type": "function",
                "function": {
                    "name": "search_cars_by_budget",
                    "description": "Ø¬Ø³ØªØ¬ÙˆÛŒ Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨ÙˆØ¯Ø¬Ù‡ Ú©Ø§Ø±Ø¨Ø± (ÛµÙª Ø¨Ø§Ù„Ø§ØªØ± ØªØ§ Û±Û°Ùª Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Ø¨ÙˆØ¯Ø¬Ù‡)",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "budget": {
                                "type": "integer",
                                "description": "Ø¨ÙˆØ¯Ø¬Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ ØªÙˆÙ…Ø§Ù†"
                            }
                        },
                        "required": ["budget"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "search_car_price_by_name",
                    "description": "Ø¬Ø³ØªØ¬ÙˆÛŒ Ø®ÙˆØ¯Ø±Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù… Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ·Ø¨ÛŒÙ‚ ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "car_name": {
                                "type": "string",
                                "description": "Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ"
                            }
                        },
                        "required": ["car_name"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_current_shamsi_datetime",
                    "description": "Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø´Ù…Ø³ÛŒ (ÙØ§Ø±Ø³ÛŒ)",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            }
        ]
    
    def get_conversation_history(self, conversation: Conversation, max_messages: int = 50) -> List[Dict]:
        """
        Get conversation history for context
        
        Args:
            conversation: Conversation object
            max_messages: Maximum number of recent messages to include
            
        Returns:
            List of message dictionaries for AI context
        """
        messages = conversation.messages.order_by('-created_at')[:max_messages]
        history = []
        
        for message in reversed(messages):  # Reverse to get chronological order
            role = "user" if message.message_type == "user" else "assistant"
            history.append({
                "role": role,
                "content": message.content
            })
        
        return history
    
    def _call_function(self, function_name: str, arguments: Dict) -> str:
        """
        Call the specified function with given arguments
        
        Args:
            function_name: Name of the function to call
            arguments: Function arguments
            
        Returns:
            Function result as string
        """
        try:
            if function_name == "search_cars_by_budget":
                budget = arguments.get("budget")
                
                cars = self.car_search_service.search_cars_by_budget(budget)
                
                if not cars:
                    return f"Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù‡ÛŒÚ† Ø®ÙˆØ¯Ø±ÙˆÛŒÛŒ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¨ÙˆØ¯Ø¬Ù‡ {self.car_search_service._format_price(budget)} ÛŒØ§ÙØª Ù†Ø´Ø¯."
                
                result = f"Ø¨Ø§ Ø¨ÙˆØ¯Ø¬Ù‡ {self.car_search_service._format_price(budget)}ØŒ {len(cars)} Ø®ÙˆØ¯Ø±Ùˆ Ù¾ÛŒØ¯Ø§ Ø´Ø¯:\n\n"
                
                for i, car in enumerate(cars[:10], 1):  # Show top 10 results
                    result += f"{i}. {car['car_name']} - {car['price_formatted']}\n"
                
                if len(cars) > 10:
                    result += f"\nÙˆ {len(cars) - 10} Ø®ÙˆØ¯Ø±ÙˆÛŒ Ø¯ÛŒÚ¯Ø±..."
                
                return result
                
            elif function_name == "search_car_price_by_name":
                car_name = arguments.get("car_name")
                
                cars = self.car_search_service.search_car_price_by_name(car_name)
                
                if not cars:
                    return f"Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø®ÙˆØ¯Ø±ÙˆÛŒÛŒ Ø¨Ø§ Ù†Ø§Ù… '{car_name}' Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."
                
                result = f"Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ Ù†Ø§Ù… '{car_name}' Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯:\n\n"
                
                for i, car in enumerate(cars[:10], 1):  # Show top 10 results
                    result += f"{i}. {car['car_name']} - {car['price_formatted']}\n"
                
                if len(cars) > 10:
                    result += f"\nÙˆ {len(cars) - 10} Ø®ÙˆØ¯Ø±ÙˆÛŒ Ø¯ÛŒÚ¯Ø±..."
                
                return result
                
            elif function_name == "get_current_shamsi_datetime":
                # Get current datetime and convert to Shamsi
                current_datetime = datetime.now()
                shamsi_datetime = jdatetime.datetime.fromgregorian(datetime=current_datetime)
                
                # Format the Shamsi datetime
                shamsi_date = f"{shamsi_datetime.year}/{shamsi_datetime.month:02d}/{shamsi_datetime.day:02d}"
                shamsi_time = f"{shamsi_datetime.hour:02d}:{shamsi_datetime.minute:02d}"
                
                # Get Persian day name
                persian_days = {
                    0: "Ø´Ù†Ø¨Ù‡",
                    1: "ÛŒÚ©Ø´Ù†Ø¨Ù‡", 
                    2: "Ø¯ÙˆØ´Ù†Ø¨Ù‡",
                    3: "Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡",
                    4: "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡",
                    5: "Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡",
                    6: "Ø¬Ù…Ø¹Ù‡"
                }
                day_name = persian_days[shamsi_datetime.weekday()]
                
                return f"ðŸ“… ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ: {day_name} {shamsi_date} - Ø³Ø§Ø¹Øª {shamsi_time}"
                
            else:
                return f"ØªØ§Ø¨Ø¹ {function_name} Ø´Ù†Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯."
                
        except Exception as e:
            print(f"Error calling function {function_name}: {str(e)}")
            return f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ {function_name}: {str(e)}"
    
    def generate_response(
        self, 
        user_message: str, 
        conversation: Conversation,
        user_context: Optional[Dict] = None
    ) -> str:
        """
        Generate AI response for user message using GPT-4.1 with function calling
        
        Args:
            user_message: The user's message
            conversation: Conversation object for context
            user_context: Additional user context (subscription info, etc.)
            
        Returns:
            Generated AI response
        """
        try:
            # Get conversation history
            conversation_history = self.get_conversation_history(conversation)
            
            # Build system prompt
            system_prompt = self._build_system_prompt(user_context)
            
            # Prepare messages for AI
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(conversation_history)
            messages.append({"role": "user", "content": user_message})
            
            print(f"Calling Aval AI API with base_url: {self.base_url}")
            print(f"Messages to send: {messages}")
            
            # Try GPT-4.1 models in order of preference
            gpt4_models = [
                "gpt-4.1",  # Primary GPT-4.1 model
            ]
            
            response = None
            used_model = None
            
            for model in gpt4_models:
                try:
                    print(f"Trying model: {model}")
                    
                    # First call - check if function calling is needed
                    response = self.client.chat.completions.create(
                        model=model,
                        messages=messages,
                        tools=self.available_functions,
                        tool_choice="auto",
                        max_tokens=16000,
                        temperature=0.7,
                        stream=False
                    )
                    
                    used_model = model
                    print(f"Successfully used model: {model}")
                    break
                    
                except Exception as model_error:
                    print(f"Failed with {model}: {model_error}")
                    continue
            
            if response is None:
                raise Exception("All GPT models failed to respond")
            
            # Check if function calling is needed
            if response.choices[0].message.tool_calls:
                # Handle function calls
                tool_calls = response.choices[0].message.tool_calls
                function_results = []
                
                for tool_call in tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    print(f"Calling function: {function_name} with args: {function_args}")
                    
                    # Call the function
                    function_result = self._call_function(function_name, function_args)
                    function_results.append(function_result)
                
                # Add function results to messages and get final response
                messages.append(response.choices[0].message)
                
                for i, tool_call in enumerate(tool_calls):
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": function_results[i]
                    })
                
                # Get final response from AI
                final_response = self.client.chat.completions.create(
                    model=used_model,
                    messages=messages,
                    max_tokens=15000,
                    temperature=0.7,
                    stream=False
                )
                
                ai_response = final_response.choices[0].message.content.strip()
                
            else:
                # No function calling needed
                ai_response = response.choices[0].message.content.strip()
            
            # Log the interaction for debugging
            # self._log_interaction(conversation, user_message, ai_response, messages, used_model)
            
            return ai_response
            
        except Exception as e:
            error_msg = f"Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ø´Ù…Ø§ Ù¾ÛŒØ´ Ø¢Ù…Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
            print(f"AI Agent Error: {str(e)}")
            print(f"Error type: {type(e)}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            return error_msg
    
    def _build_system_prompt(self, user_context: Optional[Dict] = None) -> str:
        """
        Build system prompt for the AI agent
        
        Args:
            user_context: User context information
            
        Returns:
            System prompt string
        """
        base_prompt = """Ø´Ù…Ø§ Ø±Ø¨Ø§Øª Ø®ÙˆØ¯Ø±ÙˆÛŒØ§Ø± Ù‡Ø³ØªÛŒØ¯ØŒ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ø±Ùˆ Ø¬Ù‡Øª Ø®Ø±ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨ÙˆØ¯Ø¬Ù‡ . 

ÙˆØ¸Ø§ÛŒÙ Ø´Ù…Ø§:
- Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø®ÙˆØ¯Ø±Ùˆ
- Ú©Ù…Ú© Ø¯Ø± Ø¬Ø³ØªØ¬Ùˆ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§
- Ø§Ø±Ø§Ø¦Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‚ÛŒÙ…Øª Ùˆ Ù…Ø´Ø®ØµØ§Øª
- Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ø¯Ø± Ø®Ø±ÛŒØ¯ Ø®ÙˆØ¯Ø±Ùˆ
- Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª ÙÙ†ÛŒ Ø®ÙˆØ¯Ø±Ùˆ

Ù†Ú©Ø§Øª Ù…Ù‡Ù…:
- Ù‡Ù…ÛŒØ´Ù‡ Ø§Ø¨ØªØ¯Ø§ Ø¨ÙˆØ¯Ø¬Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯
- Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯
- Ø¨Ù‡ Ù‡ÛŒÚ† Ø¹Ù†ÙˆØ§Ù† Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª ØºÛŒØ± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø®ÙˆØ¯Ø±Ùˆ Ù¾Ø§Ø³Ø® Ù†Ø¯Ù‡ÛŒØ¯. Ø¯Ø± Ø¬ÙˆØ§Ø¨ Ø³ÙˆØ§Ù„Ø§Øª Ù†Ø§Ù…Ø±Ø¨ÙˆØ· ÙÙ‚Ø· Ø¨Ú¯Ùˆ Ù†Ù…ÛŒØ¯Ø§Ù†Ù… Ùˆ Ø§Ø·Ù„Ø§Ø¹ÛŒ Ù†Ø¯Ø§Ø±Ù…
- Ø§Ø² Ù„Ø­Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±ØŒ Ø³ÙˆØ§Ù„ Ø¨Ù¾Ø±Ø³ÛŒØ¯
- Ø¬ÙˆØ§Ø¨ Ù…ÙÛŒØ¯ Ùˆ Ú©ÙˆØªØ§Ù‡ Ø¨Ø§Ø´Ø¯
- Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø§Ø¦Ù‡ Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§ØŒ Ø­ØªÙ…Ø§Ù‹ ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø±Ø§ Ø°Ú©Ø± Ú©Ù†ÛŒØ¯
- Ø¨Ø¹Ø¯ Ø§ÛŒÙ†Ú©Ù‡ Ø®ÙˆØ¯Ø±Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨ÙˆØ¯Ø¬Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù…Ø¹Ø±ÙÛŒ Ù…ÛŒÚ©Ù†ÛŒ Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ù‡Ø§ Ù‡Ù… Ø­ØªÙ…Ø§ Ø°Ú©Ø± Ú©Ù†

ØªÙˆØ§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯:

1. Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø®ÙˆØ¯Ø±Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨ÙˆØ¯Ø¬Ù‡ØŒ Ø§Ø² ØªØ§Ø¨Ø¹ search_cars_by_budget Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
- Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ú©Ù‡ ÛµÙª Ø¨Ø§Ù„Ø§ØªØ± ØªØ§ Û±Û°Ùª Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Ø¨ÙˆØ¯Ø¬Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù‡Ø³ØªÙ†Ø¯ØŒ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯
- Ø¨ÙˆØ¯Ø¬Ù‡ Ø±Ø§ Ø¨Ù‡ ØªÙˆÙ…Ø§Ù† Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯ (Ù…Ø«Ù„Ø§Ù‹ 500 Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù† = 500000000 ØªÙˆÙ…Ø§Ù†)

2. Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù…ØŒ Ø§Ø² ØªØ§Ø¨Ø¹ search_car_price_by_name Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
- Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ú©Ù‡ Ù†Ø§Ù…Ø´Ø§Ù† Ø´Ø¨ÛŒÙ‡ Ø¨Ù‡ Ù†Ø§Ù… Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ Ú©Ø§Ø±Ø¨Ø± Ø§Ø³ØªØŒ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯
- Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ·Ø¨ÛŒÙ‚ ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
- Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§ØªÛŒ Ù…Ø«Ù„ "Ù‚ÛŒÙ…Øª Ù¾Ú˜Ùˆ 207 Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ" ÛŒØ§ "Ø¯Ù†Ø§ Ù¾Ù„Ø§Ø³ Ú†Ù†Ø¯ Ø§Ø³ØªØŸ" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯

3. Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒØŒ Ø§Ø² ØªØ§Ø¨Ø¹ get_current_shamsi_datetime Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
- Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø´Ù…Ø³ÛŒ (ÙØ§Ø±Ø³ÛŒ) Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯
- Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø§Ø¦Ù‡ Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§ØŒ Ø­ØªÙ…Ø§Ù‹ Ø§Ø² Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ØªØ§ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø¯Ø§Ù†Ø¯ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú†Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ Ø§Ø³Øª

Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¨ÙˆØ¯Ø¬Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø¹Ù„Ø§Ù… Ú©Ø±Ø¯ØŒ Ø­ØªÙ…Ø§Ù‹ Ø§Ø² ØªØ§Ø¨Ø¹ search_cars_by_budget Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ÙÛŒØ¯ Ùˆ Ù…Ù†Ø¸Ù… Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.

Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù†Ø§Ù… Ø®ÙˆØ¯Ø±ÙˆÛŒ Ø®Ø§ØµÛŒ Ø±Ø§ Ù¾Ø±Ø³ÛŒØ¯ØŒ Ø§Ø² ØªØ§Ø¨Ø¹ search_car_price_by_name Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ Ù‚ÛŒÙ…Øª Ø¢Ù† Ø®ÙˆØ¯Ø±Ùˆ Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.

Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø§Ø¦Ù‡ Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‚ÛŒÙ…ØªØŒ Ø­ØªÙ…Ø§Ù‹ ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ get_current_shamsi_datetime Ø°Ú©Ø± Ú©Ù†ÛŒØ¯."""

        # Add user context if available
        if user_context:
            context_info = []
            if user_context.get('subscription_end'):
                context_info.append(f"Ø§Ø´ØªØ±Ø§Ú© Ú©Ø§Ø±Ø¨Ø± ØªØ§ {user_context['subscription_end']} ÙØ¹Ø§Ù„ Ø§Ø³Øª")
            if user_context.get('plan_name'):
                context_info.append(f"Ù†ÙˆØ¹ Ø§Ø´ØªØ±Ø§Ú©: {user_context['plan_name']}")
            
            if context_info:
                base_prompt += f"\n\nØ§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±:\n" + "\n".join(context_info)
        
        return base_prompt
    
    def test_connection(self) -> bool:
        """
        Test connection to Aval AI API with GPT-4.1
        
        Returns:
            True if connection successful, False otherwise
        """
        try:
            # Try GPT-4.1 first, then fallback to other models
            gpt4_models = ["gpt-4.1", "gpt-4.1-turbo", "gpt-4", "gpt-3.5-turbo"]
            
            for model in gpt4_models:
                try:
                    response = self.client.chat.completions.create(
                        model=model,
                        messages=[{"role": "user", "content": "Ø³Ù„Ø§Ù…"}],
                        max_tokens=10
                    )
                    print(f"Connection test successful with model: {model}")
                    return True
                except Exception as e:
                    print(f"Connection test failed with {model}: {e}")
                    continue
            
            return False
        except Exception as e:
            print(f"AI API Connection Test Failed: {str(e)}")
            return False


# Global AI agent instance
_ai_agent = None

def get_ai_agent() -> KhodroyarAIAgent:
    """
    Get or create global AI agent instance
    
    Returns:
        KhodroyarAIAgent instance
    """
    global _ai_agent
    if _ai_agent is None:
        _ai_agent = KhodroyarAIAgent()
    return _ai_agent 